{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMyhOKRLVDgQa5Puk+i6VNQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Trafilatura with PI protection\n","*ECE 570 Course Project*\n","\n","Trafilatura is an open-source generic extraction tool for extracting meaningful content from html inputs. It was developed as a tool for building web corpora to train machine learning models. https://github.com/adbar/trafilatura\n","\n","Trafilatura does not have any functionality to remove PII from its extractions. It is crucial to keep specific real PII out of corpora, so this project attempts to achieve that. The piiranha model for PII detection (https://huggingface.co/iiiorg/piiranha-v1-detect-personal-information) is used to redact PII from trafilatura's extractions before returning the extracted content."],"metadata":{"id":"N8LzZ3y3vUrk"}},{"cell_type":"markdown","source":["Import libraries:"],"metadata":{"id":"QNAeR2hmwRlB"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T2HvhKYOu9Ot","executionInfo":{"status":"ok","timestamp":1730063071645,"user_tz":240,"elapsed":3676,"user":{"displayName":"Emma Teff","userId":"08710051236758747688"}},"outputId":"2d5e4f09-7ed7-4580-8f01-707b352528d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: trafilatura in /usr/local/lib/python3.10/dist-packages (1.12.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from trafilatura) (2024.8.30)\n","Requirement already satisfied: courlan>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from trafilatura) (1.3.1)\n","Requirement already satisfied: htmldate>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from trafilatura) (1.9.1)\n","Requirement already satisfied: justext>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from trafilatura) (3.0.1)\n","Requirement already satisfied: lxml>=5.2.2 in /usr/local/lib/python3.10/dist-packages (from trafilatura) (5.3.0)\n","Requirement already satisfied: charset-normalizer>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from trafilatura) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from trafilatura) (2.2.3)\n","Requirement already satisfied: babel>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from courlan>=1.2.0->trafilatura) (2.16.0)\n","Requirement already satisfied: tld>=0.13 in /usr/local/lib/python3.10/dist-packages (from courlan>=1.2.0->trafilatura) (0.13)\n","Requirement already satisfied: dateparser>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from htmldate>=1.8.1->trafilatura) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from htmldate>=1.8.1->trafilatura) (2.8.2)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura) (2024.2)\n","Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura) (2024.9.11)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura) (5.2)\n","Requirement already satisfied: lxml-html-clean in /usr/local/lib/python3.10/dist-packages (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura) (0.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->htmldate>=1.8.1->trafilatura) (1.16.0)\n"]}],"source":["!pip install trafilatura\n","import trafilatura\n","import torch\n","from transformers import AutoTokenizer, AutoModelForTokenClassification"]},{"cell_type":"markdown","source":["Load model:"],"metadata":{"id":"5FVwcveAwUNy"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"iiiorg/piiranha-v1-detect-personal-information\")\n","model = AutoModelForTokenClassification.from_pretrained(\"iiiorg/piiranha-v1-detect-personal-information\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uS8KCCXSwP64","executionInfo":{"status":"ok","timestamp":1730063075205,"user_tz":240,"elapsed":977,"user":{"displayName":"Emma Teff","userId":"08710051236758747688"}},"outputId":"71b3cf0d-0e00-4e2a-afa5-289ed0175f30"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DebertaV2ForTokenClassification(\n","  (deberta): DebertaV2Model(\n","    (embeddings): DebertaV2Embeddings(\n","      (word_embeddings): Embedding(251000, 768, padding_idx=0)\n","      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","      (dropout): StableDropout()\n","    )\n","    (encoder): DebertaV2Encoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","      )\n","      (rel_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=18, bias=True)\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Obtain a url to perform an extraction from:"],"metadata":{"id":"5k7eUYB4wZn6"}},{"cell_type":"code","source":["print(\"\\nTrafilatura w/ PII Protection!\\n\")\n","url = input(\"Please enter a URL to extract content from: \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGcS1dO5wkDM","executionInfo":{"status":"ok","timestamp":1730063084061,"user_tz":240,"elapsed":5414,"user":{"displayName":"Emma Teff","userId":"08710051236758747688"}},"outputId":"4acfe480-e1e4-45ed-da38-0b6e1b5d5944"},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Trafilatura w/ PII Protection!\n","\n","Please enter a URL to extract content from: https://engineering.purdue.edu/ece404/\n"]}]},{"cell_type":"markdown","source":["Perform the extraction:"],"metadata":{"id":"DbP7skXSwq7C"}},{"cell_type":"code","source":["# Use PIIranha to detect and redact PII\n","# if the parameter aggregate_redaction is true, PII is replaced with \"[redacted]\"\n","# if aggregate_redaction is false, PII is replaced with more detailed tags such as \"[I-EMAIL]\", \"[I-SURNAME]\", etc.\n","def mask_pii(text, aggregate_redaction=True):\n","    # Tokenize input text\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    # Get the model predictions\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    # Get the predicted labels\n","    predictions = torch.argmax(outputs.logits, dim=-1)\n","\n","    # Convert token predictions to word predictions\n","    encoded_inputs = tokenizer.encode_plus(text, return_offsets_mapping=True, add_special_tokens=True)\n","    offset_mapping = encoded_inputs['offset_mapping']\n","\n","    masked_text = list(text)\n","    is_redacting = False\n","    redaction_start = 0\n","    current_pii_type = ''\n","    count = 0\n","\n","    for i, (start, end) in enumerate(offset_mapping):\n","        if start == end:  # Special token\n","            continue\n","\n","        label = predictions[0][i].item()\n","        if label != model.config.label2id['O']:  # Non-O label\n","            pii_type = model.config.id2label[label]\n","            if not is_redacting:\n","                is_redacting = True\n","                redaction_start = start\n","                current_pii_type = pii_type\n","            elif not aggregate_redaction and pii_type != current_pii_type:\n","                # End current redaction and start a new one\n","                apply_redaction(masked_text, redaction_start, start, current_pii_type, aggregate_redaction)\n","                redaction_start = start\n","                current_pii_type = pii_type\n","                count += 1\n","        else:\n","            if is_redacting:\n","                apply_redaction(masked_text, redaction_start, end, current_pii_type, aggregate_redaction)\n","                is_redacting = False\n","                count += 1\n","\n","    # Handle case where PII is at the end of the text\n","    if is_redacting:\n","        apply_redaction(masked_text, redaction_start, len(masked_text), current_pii_type, aggregate_redaction)\n","        count += 1\n","\n","    return ''.join(masked_text), count\n","\n","# helper function for replacing the detected PII with tags\n","def apply_redaction(masked_text, start, end, pii_type, aggregate_redaction):\n","    for j in range(start, end):\n","        masked_text[j] = ''\n","    if aggregate_redaction:\n","        masked_text[start] = '[redacted]'\n","    else:\n","        masked_text[start] = f'[{pii_type}]'\n","\n","downloaded_html = trafilatura.fetch_url(url)\n","if downloaded_html:\n","    # Extract main content from the downloaded HTML\n","    extracted_content = trafilatura.extract(downloaded_html, favor_recall=True)\n","\n","    if extracted_content:\n","        filtered_content, pii_instance_count = mask_pii(extracted_content, aggregate_redaction=False)\n","        print(f\"\\nThere were a total of {pii_instance_count} redactions of PII made:\\n\")\n","        print(filtered_content)\n","    else:\n","        print(\"Content extraction failed.\")\n","else:\n","    print(\"Failed to fetch content from the URL.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5fAeaO4ws4H","executionInfo":{"status":"ok","timestamp":1730063089981,"user_tz":240,"elapsed":2837,"user":{"displayName":"Emma Teff","userId":"08710051236758747688"}},"outputId":"b6abaed1-4da5-4f48-bf75-73ef5c21f281"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"output_type":"stream","name":"stdout","text":["\n","There were a total of 13 redactions of PII made.\n","\n","Instructor:[I-GIVENNAME][I-SURNAME]\n","Professor, ECE\n","E-mail:[I-EMAIL]You must place the string 'ece404' in the subject line to get past your instructor's notorious spam filter)\n","Graduate TAs:[I-GIVENNAME][I-SURNAME]-\n","E-mail:[I-USERNAME][I-EMAIL][I-USERNAME]\n","Joseph Wang\n","-\n","E-mail:[I-USERNAME][I-EMAIL]\n","Adrien Dubois\n","-\n","E-mail:[I-USERNAME][I-EMAIL][I-USERNAME]\n","Lecture Location and Time\n","-\n","TuTh: 6:00 PM - 7:15 PM, PHYS 112\n","Course Description\n","-\n","Beyond question, computer and network security has emerged as one of\n","the most important subjects of study in modern times. Even the minutest\n","details of our lives now depend on our computers and networks working\n","with our trust that the information that is private to us will not fall\n","in the hands of those with ill intent. The two major components of\n","computer and network security are cryptography and what is known as\n","systems-oriented security. For a good education in computer and network\n","security, you have no choice but to learn them both. That, then, is the\n","goal of this course: To provide a balanced introduction to both cryptography\n","and the systems-oriented issues. The systems-oriented issues we will cover\n","in this course include Denial-of-Service attacks, DNS Cache Poisoning attacks,\n","Buffer Overflow attacks, Dictionary attacks, attacks with viruses, worms, and\n","Trojans, etc.\n","Homework and Exam Credit:\n","-\n","You will earn 50% of your credit from homework assignments (including programming assignments) and 50% from three exams.\n","NOTE: All the homework assignments and announcements will be posted on Brightspace for Spring 2024. Do not use the links below.\n","Course Materials:\n"]}]}]}